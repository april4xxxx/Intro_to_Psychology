## Prototyping
Prototyping Overview
- Prototyping is a method for quickly creating design approximations to gather feedback.
- It facilitates conversations among stakeholders, including colleagues, clients, users, and designers.
- Prototypes can vary in form and purpose, helping to **explore different design questions**.

Iterative Design Process
- Prototyping is an **iterative** process where **multiple alternatives** are explored based on **feedback**.
- Early prototypes should be **incomplete** and **easily changeable** to encourage **rapid learning and adaptation**.

Prototyping in Various Contexts
- Prototyping is applicable to both small and large projects, such as software and aircraft design.
- The goal is to ask the **right questions** and **gather valuable insights** throughout the design process.

---
##  Evaluate Designs with People
Purpose 
Evaluating designs with users provides **critical insights** that can lead to new ideas, **necessary changes**, and **bug fixes**. It helps designers understand complex and subjective user behaviors and **preferences**.

### Key Questions in Evaluation
- **Usability**: Can people figure out how to use it?
- **User Experience**: Do they swear or giggle when using the interface?
- **Comparison**: How does this design compare to another?
- **Impact of Changes**: If we change the UI, how does that change people's behavior?

### Methods for User Evaluation
#### Common Methods
1. **Usability Studies**: Observing users in a controlled environment.
    - **Challenge**: Designers often have blinders to a system's quirks. Real-world users have different tasks, goals, and motivations.
    - **Bias**: Beware of the "please-the-experimenter" bias.
2. **Surveys**: A quick way to get feedback from many people.
    - **Limitation**: There is often a difference between what people say and what they do.
3. **Focus Groups**: A small group discussion about designs.
    - **Benefit**: Can yield diverse insights.
    - **Risk**: Can lead to biased responses due to group dynamics.

#### Advanced & Observational Methods
1. **Expert Feedback**: Getting feedback from experienced individuals.
    - **Examples**: Peer critique, dogfooding [^1], heuristic evaluation.
2. **Participant Observation**: Observing users in their natural environment to see their actual practices, as opposed to self-reported behavior. [UXCAM]
3. **Comparative Experiments**: Testing multiple design options against each other to measure effectiveness and user experience (e.g., testing how the order of search results affects clicks).

### General Issues to Consider in Evaluation
- **Reliability/Precision**: Are the results consistent and repeatable?
- **Generalizability**: Do the findings apply to a broader population?
- **Realism**: How well does the evaluation setting mimic the real world?
- **Comparison**: Is there a clear baseline or alternative for comparison?
- **Work Involved**: What are the resource and time costs of the evaluation?



[^1]: "dogfooding" (also known as "eating your own dog food") is the practice where a company's employees use their own product or service in their day-to-day work.

